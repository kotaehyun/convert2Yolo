{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotaehyun/convert2Yolo/blob/main/YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ycvZllVwUN"
      },
      "source": [
        "#**1. YOLO**\n",
        "* 이미지 분류, 객체 탐지, 인스턴스 분할 작업에 사용할 수 있는 모델\n",
        "<center><img src='https://drive.google.com/uc?id=1yR--JjzSQ94_279aN2_UltkjzFMDPocB' width='400'></center>\n",
        "\n",
        "* YOLO는 2015년 Joseph Redmond가 처음 출시한 이후 컴퓨터 비전 커뮤니티에 의해 성장\n",
        "* 초기버전(1~4)에서의 YOLO는 Redmond가 작성한 커스텀 딥러닝 프레임워크인 Darknet에서 유지\n",
        "* YOLOv3 레포를 PyTorch로 작성하여 Ultralytics에서 YOLOv5를 출시\n",
        "* 유연한 Python 구조 덕분에 YOLOv5는 SOTA 레포가 되었음\n",
        "* Ultralytics는 2023년 1월에 YOLOv8을 출시, 2024년 2월에 YOLOv9을 출시"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z81vWkcV8MR"
      },
      "source": [
        "#**2. 실습 데이터 준비**\n",
        "* PascalVOC 2007\n",
        "    * 분류와 객체 검출을 위해 만들어진 데이터셋\n",
        "    * 객체 분할도 가능하지만, 더 최신 버전의 데이터셋을 사용하기 권장\n",
        "    * 총 20개의 클래스를 가지고 있음\n",
        "        * Person: person\n",
        "        * Animal: bird, cat, cow, dog, horse, sheep\n",
        "        * Vehicle: aeroplane, bicycle, boat, bus, car, motorbike, train\n",
        "        * Indoor: bottle, chair, dining table, potted plant, sofa, tv/monitor\n",
        "    * 학습 데이터\n",
        "        * train: 2501장\n",
        "        * val: 2510장\n",
        "        * test: 4952장\n",
        "    \n",
        "> 학습 데이터가 너무 적어서 train과 val를 합쳐서 학습시킨 후, 데스트 데이터를 검증 데이터셋으로 사용  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfMl3G-GZHRg",
        "outputId": "6926b8d1-0a1e-4582-e61d-b2e3c96f4de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-05 06:43:26--  http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar [following]\n",
            "--2024-04-05 06:43:26--  https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460032000 (439M) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  42.5MB/s    in 11s     \n",
            "\n",
            "2024-04-05 06:44:04 (41.3 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhygjNosZOle",
        "outputId": "611570f9-af5d-4652-8f36-52e5cb9c7265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-05 08:04:08--  http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar [following]\n",
            "--2024-04-05 08:04:09--  https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/x-tar]\n",
            "Saving to: ‘VOCtest_06-Nov-2007.tar’\n",
            "\n",
            "VOCtest_06-Nov-2007  93%[=================>  ] 400.49M  16.4MB/s    eta 3s     "
          ]
        }
      ],
      "source": [
        "!wget http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCAb52B4aU3p"
      },
      "source": [
        "```\n",
        "pascal_datasets\n",
        "pascal_datasets/trainval\n",
        "pascal_datasets/test\n",
        "pascal_datasets/VOC\n",
        "pascal_datasets/VOC/images\n",
        "pascal_datasets/VOC/labels\n",
        "pascal_datasets/VOC/images/train2007\n",
        "pascal_datasets/VOC/images/val2007\n",
        "pascal_datasets/VOC/images/test2007\n",
        "pascal_datasets/VOC/labels/train2007\n",
        "pascal_datasets/VOC/labels/val2007\n",
        "pascal_datasets/VOC/labels/test2007\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2qGEvB-ZlJv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Vi6GvxaQCt"
      },
      "outputs": [],
      "source": [
        "root = Path('./pascal_datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWaZNzZVapx4"
      },
      "outputs": [],
      "source": [
        "# parents=True로 설정되면 pascal_datasets를 생성하고 아래 trainval를 생성\n",
        "# 디렉토리 구조가 없는 경우 전체 경로를 한 번에 생성\n",
        "Path('./pascal_datasets/trainval').mkdir(parents=True, exist_ok=True)\n",
        "Path('./pascal_datasets/test').mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X-hbW9BbPne"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "pascal_datasets/VOC/images\n",
        "pascal_datasets/VOC/labels\n",
        "pascal_datasets/VOC/images/train2007\n",
        "pascal_datasets/VOC/images/val2007\n",
        "pascal_datasets/VOC/images/test2007\n",
        "pascal_datasets/VOC/labels/train2007\n",
        "pascal_datasets/VOC/labels/val2007\n",
        "pascal_datasets/VOC/labels/test2007\n",
        "경로를 한번에 구조를 만드는 알고리즘을 작성해보자.\n",
        "(단, 2중 for문을 사용)\n",
        "'''\n",
        "for path1 in ('images', 'labels'):\n",
        "    for path2 in ('train2007', 'val2007', 'test2007'):\n",
        "        new_path = root / 'VOC' / path1 / path2\n",
        "        new_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0nsg04ue5HQ"
      },
      "outputs": [],
      "source": [
        "!tar -xvf VOCtrainval_06-Nov-2007.tar -C ./pascal_datasets/trainval/\n",
        "!tar -xvf VOCtest_06-Nov-2007.tar -C ./pascal_datasets/test/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkr33rDQfUhN"
      },
      "source": [
        "#**3. YOLO 포멧으로 변경하기**\n",
        "* xml에서 좌표(XMin, YMin, XMax, YMax)를 YOLO 모델에서 사용하기 위해 포멧 변경이 필요\n",
        "* YOLO 형식: (클래스번호, X의 center좌표, Y의 center좌표, 너비, 높이)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbu1BK-4gO1D"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ssaru/convert2Yolo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeF9jIYbgULs"
      },
      "outputs": [],
      "source": [
        "%cd convert2Yolo\n",
        "%pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUvmF9CGg19j"
      },
      "source": [
        "#**4. names 파일**\n",
        "* 머신러닝, 딥러닝 모델이 데이터셋 내의 클래스를 인식하고 구분할 수 있도록 클래스 이름을 정의하는데 사용되는 파일 형식\n",
        "* Darknet 프레임워크와 머신러닝 라이브러리와 함께 사용\n",
        "* YOLO와 같은 유명한 객체 탐지 알고리즘을 구현하는데 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlISbgQml4eE"
      },
      "outputs": [],
      "source": [
        "# trainval 데이터 yolo 포멧 변환\n",
        "!python3 example.py --datasets VOC --img_path ./pascal_datasets/trainval/VOCdevkit/VOC2007/JPEGImages/ --label /content/pascal_datasets/trainval/VOCdevkit/VOC2007/Annotations/ --convert_output_path /content/pascal_datasets/VOC/labels/train2007 --img_type \".jpg\" --manifest_path /content/ --cls_list_file ./voc.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td-4F7dlnpuV"
      },
      "outputs": [],
      "source": [
        "# test 데이터 yolo 포멧 변환\n",
        "!python3 example.py --datasets VOC --img_path ./pascal_datasets/test/VOCdevkit/VOC2007/JPEGImages/ --label /content/pascal_datasets/test/VOCdevkit/VOC2007/Annotations/ --convert_output_path /content/pascal_datasets/VOC/labels/test2007 --img_type \".jpg\" --manifest_path /content/ --cls_list_file ./voc.names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hErQn23boFg5"
      },
      "source": [
        "### 문제\n",
        "PascalVOC 제공 파일로 train, val 라벨 분할\n",
        "* /content/pascal_datasets/trainval/VOCdevkit/VOC2007/ImageSets/Main/val.txt 를 읽어서 /content/pascal_datasets/VOC/labels/train2007/ 파일을 /content/pascal_datasets/VOC/labels/val2007/ 로 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-FbDWWjwo8kw"
      },
      "outputs": [],
      "source": [
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "HDEPwbNAr1W-",
        "outputId": "ebb44c9f-a280-4751-c1ef-5d1b9fc34f83"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/pascal_datasets/VOC/labels/train2007//000005.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pascal_datasets/VOC/labels/train2007//000005.txt' -> '/content/pascal_datasets/VOC/labels/val2007//000005.txt'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c50f9ac30737>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mori_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/pascal_datasets/VOC/labels/train2007/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/pascal_datasets/VOC/labels/val2007/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{ori_path}/{id}.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{mv_path}/{id}.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'파일이동 완료!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pascal_datasets/VOC/labels/train2007//000005.txt'"
          ]
        }
      ],
      "source": [
        "path = '/content/pascal_datasets/trainval/VOCdevkit/VOC2007/ImageSets/Main/val.txt'\n",
        "\n",
        "with open(path) as f:\n",
        "    image_ids = f.read().strip().split()\n",
        "    for id in image_ids:\n",
        "        ori_path = '/content/pascal_datasets/VOC/labels/train2007/'\n",
        "        mv_path = '/content/pascal_datasets/VOC/labels/val2007/'\n",
        "        shutil.move(f'{ori_path}/{id}.txt', f'{mv_path}/{id}.txt')\n",
        "print('파일이동 완료!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40vU1Qv3weD5",
        "outputId": "afb71fd3-4087-4adb-c8b1-fbe421391821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train2007 :  2501\n",
            "val2007 :  2510\n",
            "test2007 :  4952\n"
          ]
        }
      ],
      "source": [
        "# /content/pascal_datasets/trainval/VOCdevkit/VOC2007/JPEGImages\n",
        "# /content/pascal_datasets/VOC/images/train2007\n",
        "# /content/pascal_datasets/VOC/images/val2007\n",
        "\n",
        "# /content/pascal_datasets/test/VOCdevkit/VOC2007/JPEGImages\n",
        "# /content/pascal_datasets/VOC/images/test2007\n",
        "\n",
        "import os\n",
        "\n",
        "path = '/content/pascal_datasets'\n",
        "\n",
        "for folder, subset in ('trainval', 'train2007'), ('trainval', 'val2007'), ('test', 'test2007'):\n",
        "    ex_imgs_path = f'{path}/{folder}/VOCdevkit/VOC2007/JPEGImages'\n",
        "    label_path = f'{path}/VOC/labels/{subset}'\n",
        "    img_path = f'{path}/VOC/images/{subset}'\n",
        "    print(subset, \": \", len(os.listdir(label_path)))\n",
        "    for lbs_list in os.listdir(label_path):\n",
        "        shutil.move(os.path.join(ex_imgs_path, lbs_list.split('.')[0]+'.jpg'),\n",
        "                    os.path.join(img_path, lbs_list.split('.')[0]+'.jpg'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I00qdM0P3B5j"
      },
      "source": [
        "#**5. YOLOv5 다운로드 및 설치**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOH-TP0P3yah",
        "outputId": "5fe3f651-463c-46cf-b76d-ceaa93caf13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone -b v6.2 https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WO4dda832Re",
        "outputId": "62a9b04f-205c-43cc-a22b-0da377fafcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "Requirement already satisfied: numpy==1.23.0 in /usr/local/lib/python3.10/dist-packages (1.23.0)\n"
          ]
        }
      ],
      "source": [
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "!pip install numpy==1.23.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx9WzwGL4IhI",
        "outputId": "0c017d07-f5e2-458d-f07f-1f46a21ccfbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v6.2-0-gd3ea0df8 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 31.8/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhsQ5YPm4y60"
      },
      "source": [
        "#**6. WanDB를 이용한 학습 및 평가 과정 로깅**\n",
        "* https://wandb.ai/site\n",
        "* 머신러닝/딥러닝 개발자를 위한 종합적인 보조 도구\n",
        "* 딥러닝 모델 학습할 때 학습 과정에 대해 로깅을 진행\n",
        "* 손실값의 감소하는 형태를 쉽게 파악할 수 있음\n",
        "* 팀 단위로 실험 결과를 추적할 수 있도록 해주기 때문에 웹에서 편리하게 분석이 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iydPKQZ4H_gd",
        "outputId": "f4c83593-a1e4-4a8a-cd59-8a02ce6d7bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.9/264.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lW5axk9KGzV"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "j8k-gnclKNqA",
        "outputId": "e2e3b88f-e842-4d1d-ee2f-4172aafaefb1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxZsZ_5EKQIb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPsp3FZJKfMQ"
      },
      "outputs": [],
      "source": [
        "seed = 2024\n",
        "deterministic = True\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "if deterministic:\n",
        "    # 학습 및 추론 과정에서 재현성을 보장하기 위해 사용\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # 모델의 학습 및 추론 성능을 최적화하기 위해 사용\n",
        "    # True: 최적화된 알고리즘을 동적으로 선택\n",
        "    # False: 오버헤드는 발생하지 않으나 성능이 떨어짐\n",
        "    torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubc2ginALW1T"
      },
      "source": [
        "#**7. 어노테이션**\n",
        "* 어노테이션(주석)은 데이터 집합의 데이터에 정보 또는 레이블을 추가하는 프로세스\n",
        "* 컴퓨터 비전에서 이미지에서 특정 객체의 존재, 객체의 속성(색상, 크기, 모양)을 나타내는 레이블\n",
        "* 수동으로 추가하거나 컴퓨터 알고리즘을 사용하여 자동으로 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUsGGZF7OS4O"
      },
      "source": [
        "### 7-1. 어노테이션의 종류\n",
        "* Bounding Box\n",
        "    * 이미지 내에서 객체의 위치 및 크기를 정의하는 작업\n",
        "    * 객체 주위에 Box를 그리고 클래스(사람, 자동차)로 Label을 지정\n",
        "    * Object Detection에 일반적으로 사용\n",
        "    * 이미지 내에서 객체의 위치를 정의하는 간단하고 효과적인 방법\n",
        "* KeyPoint\n",
        "    * 객체 내의 특정 관심 지점을 표시하는 작업\n",
        "    * 사람 또는 동물의 이미지 내 관절의 위치를 예측하는 것이 목표인 Task에 종종 사용\n",
        "* Segmentation\n",
        "    * 이미지 내에서 객체의 경계를 정의\n",
        "    * 객체의 경계를 표시하고 인식하고 이미지 내의 객체를 분류하도록 학습\n",
        "    * 복잡한 형태의 어노테이션이지만 이미지 객체에 대한 더 자세한 정보를 모델에게 제공하므로 성능이 향상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylqVRbmIPduk"
      },
      "source": [
        "### 7-2. 어노테이션 방법\n",
        "* 수동 주석\n",
        "    * 마우스 또는 스타일러스와 같은 도구를 사용하여 이미지 내의 각 객체에 수동으로 레이블을 지정하는 작업\n",
        "* 자동 주석\n",
        "    * 컴퓨터 알고리즘을 사용하여 이미지 내의 객체에 자동으로 레이블을 지정하는 작업\n",
        "    * 가장 빠르지만 정확도가 낮음\n",
        "    * 자동 주석은 수작업 비용이 높은 대규모 데이터셋에 주석을 추가하는데 사용\n",
        "* 반자동 주석\n",
        "    * 컴퓨터 지원 도구를 사용하여 주석 프로세스의 속도를 높이는 작업\n",
        "    * 어노테이터는 도구를 사용하여 객체 주위에 경계 상자를 그릴 수 있으며, 컴퓨터는 자동으로 객체에 해당 클래스로 레이블을 지정\n",
        "    * 수동 주석보다는 빠르지만, 정확성을 보장하려면 사람의 입력과 노력이 필요함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UIyxlhHQLKH"
      },
      "source": [
        "#**8. data.yaml 파일**\n",
        "* custom_voc: Pascal voc 2007 데이터 명시 파일\n",
        "* custom_dataset: 직접 라벨링한 데스트 데이터 명시 파일\n",
        "* 파일 경로: /content/yolov/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6dv9aVbX-hy"
      },
      "source": [
        "#**9. YOLO v5 가중치 파일**\n",
        "* yolov5s.pt\n",
        "  * yolov5에 가장 작은 버전으로 경량화된 모델\n",
        "  * 작은 크기의 객체를 감지하거나 시스템 리소스가 제한된 환경에서 사용\n",
        "* yolov5m.pt\n",
        "  * 중간 크기의 모델로, 기본적인 객체 탐지와 분류에 적합\n",
        "* yolob5l.pt\n",
        "  * 큰 모델로 더 높은 정확도를 제공\n",
        "  * 크기가 큰 객체나 복잡한 시나리오에 유용\n",
        "* yolov5x,pt\n",
        "  * 가장 큰 모델로, 가장 높은 정확도를 목표로 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUWdAR2AaBdL",
        "outputId": "a04ff68e-1a1b-450c-ef2b-311c70bdd26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2024-04-02 23:14:42.782708: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-02 23:14:42.782759: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-02 23:14:42.784189: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-02 23:14:43.990791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrhxocm\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_voc.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=2024, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 563 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 632, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 503, in main\n",
            "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
            "  File \"/content/yolov5/utils/general.py\", line 453, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "AssertionError: File not found: custom_voc.yaml\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5\n",
        "!python train.py --img 640 --batch 32 --epochs 10 --data custom_voc.yaml --weights yolov5s.pt --seed 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z42dtzT9bnjw",
        "outputId": "f734b437-0bcf-45f7-8ad3-c6827433175c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/val.py\", line 395, in <module>\n",
            "    opt = parse_opt()\n",
            "  File \"/content/yolov5/val.py\", line 356, in parse_opt\n",
            "    opt.data = check_yaml(opt.data)  # check YAML\n",
            "  File \"/content/yolov5/utils/general.py\", line 427, in check_yaml\n",
            "    return check_file(file, suffix)\n",
            "  File \"/content/yolov5/utils/general.py\", line 453, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "AssertionError: File not found: custom_voc.yaml\n"
          ]
        }
      ],
      "source": [
        "# Pascal VOC 테스트 데이터로 테스\n",
        "# half: 신경망 모델의 계산을 16비트 부동 소수점 형식으로 처리으로써 메모리 사용량을 줄이고 계산 속도를 향상\n",
        "!python val.py --weights /content/yolov5/runs/train/exp/weights/best.pt --data custom_voc.yaml --img 640 --iou 0.4 --task test --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s9pQANOcJ0A",
        "outputId": "bd8e4440-b30a-4d6a-ad55-e0ddbf9547ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/val.py\", line 395, in <module>\n",
            "    opt = parse_opt()\n",
            "  File \"/content/yolov5/val.py\", line 356, in parse_opt\n",
            "    opt.data = check_yaml(opt.data)  # check YAML\n",
            "  File \"/content/yolov5/utils/general.py\", line 427, in check_yaml\n",
            "    return check_file(file, suffix)\n",
            "  File \"/content/yolov5/utils/general.py\", line 453, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "AssertionError: File not found: custom_dataset.yaml\n"
          ]
        }
      ],
      "source": [
        "# 직접 라벨링한 데스트 데이터로 테스트\n",
        "!python val.py --weights /content/yolov5/runs/train/exp/weights/best.pt --data custom_dataset.yaml --img 640 --iou 0.4 --task test --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYhAk84jcj5z",
        "outputId": "1cdf389e-f124-4c28-e17c-7c2e30bae9dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp/weights/best.pt'], source=/content/pascal_datasets/VOC/custom_datasets/obj_train_data, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.2-0-gd3ea0df8 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 257, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/detect.py\", line 252, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/detect.py\", line 93, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 330, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 80, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 998, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 445, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 426, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/runs/train/exp/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "# 이미지들에 대한 경계상자 이미지 생성\n",
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source /content/pascal_datasets/VOC/custom_datasets/obj_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KYUGa_JdbYw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}